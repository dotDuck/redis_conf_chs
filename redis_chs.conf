# redis 配置文件示例
 
# 当你需要为某个配置项指定内存大小的时候，必须要带上单位，
# 通常的格式就是 1k 5gb 4m 等这样：
#
# 1k  => 1000 bytes
# 1kb => 1024 bytes
# 1m  => 1000000 bytes
# 1mb => 1024*1024 bytes
# 1g  => 1000000000 bytes
# 1gb => 1024*1024*1024 bytes
#
# 单位是不区分大小写的，你写 1K 5GB 4M 也行
 
##################################INCLUDES###################################
 
# 在这里include一个或多个其他配置文件
# 假如说你有一个可用于所有的 redis server 的标准配置模板，
# 但针对某些 server 又需要一些个性化的设置，
# 你可以使用 include 来包含一些其他的配置文件，这对你来说是非常有用的。
#
# 但是要注意哦，include 是不能被 admin或者Redis Sentinel的config rewrite 命令改写的
# 由于 redis 总是以最后的处理行作为一个配置指令值，所以你最好是把 include 放在这个文件的最前面，
# 以避免在运行时覆盖配置的改变，相反，你就把它放在后面。
#
# include /path/to/local.conf
# include /path/to/other.conf
 
################################ 通用 #####################################
 
# 默认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes。
# 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面。
daemonize no
 
# 当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/run/redis.pid 文件里面，
# 但是你可以在这里自己指定它的文件位置。
pidfile /var/run/redis.pid
 
# 监听端口号，默认为 6379，如果你设为 0 ，redis 将不在 TCP socket 上监听任何客户端连接。
port 6379
 
# TCP 监听的最大容纳数量
#
# 在高并发的环境下，你需要把这个值调高以避免客户端连接缓慢的问题。
# Linux 内核会一声不响的把这个值缩小成 /proc/sys/net/core/somaxconn 对应的值，
# 所以你要修改这两个值才能达到你的预期。
tcp-backlog 511
 
# 默认情况下，redis 在 server 上所有有效的网络接口上监听客户端连接。
# 你如果只想让它在一个网络接口上监听，那你就绑定一个IP或者多个IP。
#
# 示例，多个IP用空格隔开:
#
# bind 192.168.1.100 10.0.0.1
# bind 127.0.0.1
 
# 指定 用于监听接入连接的unix socket 的路径。
# 没有默认值，如果不指定的话，Redis不会监听unix socket
#
# unixsocket /tmp/redis.sock
# unixsocketperm 700
 
# 指定在一个 client 空闲多少秒之后关闭连接（0 就是永不关闭）
timeout 0
 
# tcp 心跳包。
#
# 如果设置为非零，则在与客户端缺乏通讯的时候使用 SO_KEEPALIVE 发送 tcp acks 给客户端。
# 这个之所以有用，主要有两个原因：
#
# 1) 发现死的 peers
# 2) 在中间层网络设备的角度上唤醒连接
#
# 在Linux上, 指定的值（单位为秒）是用来发送ACKs的时间间隔
# 注意关闭连接的时间设置要两倍于此时间
# 在其他内核系统上这个时间间隔取决于内核设置
#
# 推荐一个合理的值就是60秒
tcp-keepalive 0
 
# 定义日志级别。
# 可以是下面的这些值：
# debug (适用于开发或测试阶段)
# verbose (大部分有用的信息，但不想debug有那么多)
# notice (适用于生产环境)
# warning (仅仅一些重要的消息被记录)
loglevel notice
 
# 指定日志文件的位置
# 为空串则强制Redis日志输出到标准输出
# 为空的话如果以守护模式运行，日志会输出到/dev/null
logfile ""
 
# 要想把日志记录到系统日志，就把它改成 yes，
# 也可以可选择性的更新其他的syslog 参数以达到你的要求
# syslog-enabled no
 
# 设置 syslog 的 identity。
# syslog-ident redis
 
# 设置 syslog 的 facility，必须是 USER 或者是 LOCAL0-LOCAL7 之间的值。
# syslog-facility local0
 
# 设置数据库的数目。
# 默认数据库是 DB 0，你可以在每个连接上使用 select <dbid> 命令选择一个不同的数据库，
# 但是 dbid 必须是一个介于 0 到 databasees - 1 之间的值
databases 16
 
################################ 快照持久化 ################################
#
#  存储DB到磁盘：
#
#  格式：save <间隔时间（秒）> <写入次数>
#
#  根据给定的时间间隔和写入次数将数据保存到磁盘
#
#  下面的例子的意思是：
#  900 秒内如果至少有 1 个 key 的值变化，则保存
#  300 秒内如果至少有 10 个 key 的值变化，则保存
#  60 秒内如果至少有 10000 个 key 的值变化，则保存
#　　
#  注意：你可以注释掉所有的 save 行来停用保存功能。
#  也可以直接一个空字符串来实现停用：
#  save ""
 
save 900 1
save 300 10
save 60 10000
 
# 默认情况下，如果 redis 最后一次的后台保存失败，redis 将停止接受写操作，
# 这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，
# 否则就会没人注意到灾难的发生。
#
# 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。
#
# 然而你要是安装了靠谱的监控，你可能不希望 redis 这样做，那你就改成 no 好了。
stop-writes-on-bgsave-error yes
 
# 是否在 dump .rdb 数据库的时候使用 LZF 压缩字符串
# 默认都设为 yes 并且一般是有益的
# 如果你希望保存子进程节省点 cpu ，你就设置它为 no ，
# 不过这个数据集可能就会比较大
rdbcompression yes
 
# 在RDB版本开始，在文件结束会放置一个CRC64校验码
# 这使得该格式对损坏更具抵抗性
# 但是在存储及加载RDB文件时会带来性能损失（10%左右）
# 关闭它可以获得最大化的性能
# 是否校验rdb文件
rdbchecksum yes
 
# 设置 dump 的文件位置
dbfilename dump.rdb
 
# 工作目录
# 例如上面的 dbfilename 只指定了文件名，
# 但是它会写入到这个目录下。这个配置项一定是个目录，而不能是文件名。
dir ./
 
################################# 主从复制 #################################
 
# 主从复制。使用 slaveof 来让一个 redis 实例成为另一个reids 实例的副本。
# 注意这个只需要在 slave 上配置。
# 尽可能快的理解Redis主从复制需要知道一些事情：
# 1）Redis主从复制是异步的，但是你可以配置master停止接受写入，当它没有被指定数
# 量的slave连接时。
# 2）如果复制连接在相对少的时间内丢失，Redis slave可以执行一次与master的部分的再同步，你也许想以一个合适的值配置这个复制的工作量大小来满足所需。
# 3）复制操作是自动的不需要用户干预的，在网络断开后slave会自动尝试重连master并且再次和他们同步。
#
# slaveof <masterip> <masterport>
 
# 如果 master 需要密码认证（下面的requirepass设置），就在这里设置
# masterauth <master-password>
 
# 当一个 slave 与 master 失去联系，或者复制正在进行的时候，
# slave 可能会有两种表现：
#
# 1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，
#    或者数据可能是空的，当发生在第一次同步的时候
#
# 2) 如果为 no ，在你执行除了 info和salveof 之外的其他命令时，
#    slave 都将返回一个 "SYNC with master in progress" 的错误，
#
slave-serve-stale-data yes
 
# 你可以配置一个 slave 实例是否接受写入操作。
# 通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
# 因为相对在 master 重新同步数据后，写入到 slave 的数据会很容易被删除。
# 但是如果客户端因为一个错误的配置写入了slave，也可能会导致一些问题。
#
# 从 redis 2.6 版起，默认 slaves 都是只读的。
#
# 注意：只读的 slaves 没有被设计成在 internet 上暴露给不受信任的客户端。
# 它仅仅是一个针对误用实例的一个保护层。
# 但是一个只读的slave还是默认可以执行所有管理命令
# 例如 CONFIG, DEBUG等等。为了限制范围你可以用’rename-command’
# 来隐藏所有管理/危险的命令，从而提升只读slaves的安全性
slave-read-only yes
 
# 主从复制同步策略：disk 或者socket.
#
# -------------------------------------------------------
# 警告：无磁盘主从复制现在为试验功能
# -------------------------------------------------------
#
# 新的slaves 和重新连接的slaves 不能仅仅通过接收差异信息继续复制进程
# 而是需要进行一个全面同步
# RDB 文件从master 传输到 slaves.
# 这个传输可以以两种方式进行
#
# 1) 磁盘备份: Redis master 创建一个写入磁盘RDB文件的新进程
# 稍后该文件会通过父进程递增地传输给slaves
# 2) 无磁盘：Redis master创建一个将RDB文件直接写入slave socket的新进程
# 根本不接触磁盘
#
# 通过磁盘备份的方式进行主从复制
# 当RDB文件创建后，更多的slaves就可以加入队列等候
# 当负责生成RDB文件的子进程完成工作时，slaves就可使用RDB文件
# 而通过无磁盘方式进行主从备份，一旦传输开始
# 新到达的slaves会被加入队列，并且只有当前传输终止后新的传输才会开始
#
# 当使用无磁盘主从复制时，为了多个slaves到达时可以平行进行传输
#master会在开始进行传输前，等待一个可配置的时间（单位秒）
#
# 当磁盘较慢而网络快（大带宽）时，无磁盘主从复制会工作的更好
repl-diskless-sync no

# 当无磁盘复制开启后，为了大量产生通过socket传输RDB给slaves的子线程
# 可以配置服务器的延迟时间
#
# 这个很重要，因为一旦传输开始，就不能服务新到达的slaves了
# 然后会排队等待到下一次RDB传输
# 所以服务器等待一个延迟，为了让更多的slaves到达
#
# 这个延时以秒来定义，默认为5秒
#设置为0秒可以完全关闭它，传输将尽可能快的开始 
repl-diskless-sync-delay 5

# Slaves 在一个预定义的时间间隔内发送 ping 命令到 server 。
# 你可以改变这个时间间隔。默认为 10 秒。
#
# repl-ping-slave-period 10
 
# 为以下项设置主从复制过期时间
#
# 1) 在SYNC期间大块的I/O传输超时，在slave方来看
# 2) Master超时，在slaves方来看 (data, pings).
# 3) Slave 超时，在masters方来看 (REPLCONF ACK pings).
#
# 这个值一定要比 repl-ping-slave-period 大
#
# repl-timeout 60
 
# SYNC后，在slave上端口上禁用TCP_NODELAY ?
#
# 如果你设置了"yes" ，Redis会使用更小的TCP包和更少的带宽传递数据给slaves
# 但是这样会延迟数据在slave上的到达时间
# 最大40毫秒在Linux kernels使用默认配置的时候
#
# "no" 则相反
# 默认情况下我们优化低延迟，但是在高流量的情况下 
# 或者master和slaves在网络上相隔很多节点时，"yes"将是个好主意
repl-disable-tcp-nodelay no
 
# 设置主从复制容量大小。这个 backlog 是一个用来在 slaves 被断开连接时
# 存放 slave 数据的 buffer，所以当一个 slave 想要重新连接，通常不希望全部重新同步，
# 只是部分同步就够了，仅仅传递 slave 在断开连接时丢失的这部分数据。
#
# 这个值越大，salve 可以断开连接的时间就越长。然后可以执行部分重新同步。
#
# backlog 只会被分配一次而且必须至少有一个slave连接
#
# repl-backlog-size 1mb
 
# 在某些时候，master 不再连接 slaves，backlog 将被释放。
# 以下的选项用来配置多少秒后释放backlog缓存，从最后一个slave断开开始计算时间
#
# 如果设置为0，意味着绝不释放backlog 。
#
# repl-backlog-ttl 3600
 
# slave优先级是Redis在INFO输出中的一个整数值
# 被用来当 master 不能正常工作的时候
# Redis Sentinel 会从 slaves 中选出一个新的 master，
# 这个值越小，就越会被优先选中，但是如果是 0 ， 那是意味着这个 slave 不可能被选中。
#
# 默认优先级为100。
slave-priority 100
 
# 可以在少于N个slaves连接时，配置master停止接受写操作
# 有小于或等于M秒的延迟才算正常连接
#
#N个slaves需要在"online" 的状态
#
# 延迟的秒数，必须<=设定的值，延迟从最后一次接收到slave的ping算起
# ping通常每秒发送一次
# 这个选项并不能保证N个复制实例会接受写入
# 但是会以设置的秒数限制失去写入操作的时间窗口，以防止没有足够的slaves可用
# 例如要求至少3个slaves 并且延迟 <= 10秒则为:
#
# min-slaves-to-write 3
# min-slaves-max-lag 10
#
# 任意一个设置为0 会禁用那一个特性
#
# 默认的min-slaves-to-write 设置为0 （禁用该特性），min-slaves-max-lag设置为10
 
################################## 安全 ###################################
 
# 需要客户端在执行任何命令前，使用AUTH <PASSWORD> 
# 这在你不信任连接到redis服务器的客户端的环境下也许有用
#
# 在需要向后兼容和大部分人不需要验证情况下（例如他们使用自己的服务器） 
# 此选项应该被注释掉
# 
# 警告：因为Redis异常的快
# 外部用户可以在一台好的服务器上一秒内尝试150k次的密码
# 这意味着你应该设置一个非常强的密码，否则很容易被暴力破解
# 
# 设置认证密码
# requirepass foobared
 
# 命令重命名
#
# 在一个共享的环境下是可以更改危险命令的名称的
# 例如 CONFIG 可以被命名为难以猜透的名字
# 但是对于内部使用的工具仍然可用
# 却对通用的客户端不可用
#
# 例如：
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# 通过把命令重命名为一个空串可以完全禁用掉该命令
#
# rename-command CONFIG ""
#
# 请注意如果修改了会记录到AOF文件或者传递给slaves的命令
# 可能会导致问题 
 
################################### 限制 ####################################
 
# 设置同一时间连接的客户端的最大数量
# 默认的限制是10000个客户端
# 然而如果Redis服务器不能配置线程文件来限制指定的最大允许连接客户端
# 最大允许连接客户端数量被设置为当前文件的最小限制值32
# (因为Redis 为内建用户预留了少量的文件描述符).
#
# 一旦达到最大限制，redis 将关闭所有的新连接
# 并发送一个‘max number of clients reached’的错误。
#
# maxclients 10000
 
# 不要使用超过此设置值的内存
# 当缓存的数据容量达到这个值， Redis 将根据你选择的
# 回收策略（见maxmemory-policy）来移除一些 keys。
#
# 如果 redis 不能根据策略移除 keys ，或者是策略被设置为 ‘noeviction’，
# redis 将开始响应错误给需要使用更多内存的命令，如SET,，LPUSH等等，
# 并继续响应只读的命令，如GET
#
# 这个选项在把Redis用作LRU缓存的时候通常是有用的，
# 或者用来严格限制实例内存使用（使用策略 'noeviction'）
#
# 警告：如果带有maxmemory限制的实例存在slaves
# 用于提供slaves功能的输出缓冲大小是不包含在该maxmemory使用计算中的
# 所以网络问题或者重新同步均不会导致移除key的循环
# 进而导致输出缓冲因为DELs溢出使更多keys删除
# 直到整个数据库完全为空（完全不用担心此情况发生！！）
#
# 简单的说，如果实例存在slaves，建议设置一个稍低的maxmemory
# 从而可以为输出缓冲留下可用的RAM（如果策略是'noeviction'则不用）
#
# 最大使用内存
# maxmemory <bytes>
 
# 最大内存策略，决定Redis在达到最大使用内存时会移除哪些keys
# 你有 5 个选择。
# 
# volatile-lru -> 使用 LRU 算法移除包含过期设置的 key 。
# allkeys-lru -> 根据 LRU 算法移除任意的 key 。
# volatile-random -> 随机移除一个带有过期设置的 key 
# allkeys-random -> 随机移除一个key，对于任意key来说
# volatile-ttl -> 移除最快要过期的key（最小TTL）
# noeviction -> 不存在过期移除，仅对写操作返回错误
# 
# 注意：对于上述的任一个策略
# Redis均会对写操作返回错误，当没有合适的keys可以移除的时候
#
#       截止到本文件发布时间，这些写操作命令包括: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# 默认策略为：
#
# maxmemory-policy noeviction
 
# LRU算法和最小TTL不是精确的算法,而是近似算法(为了节省内存)
# 所以你可以调整速度或者准确性
# Redis默认会检查5个key然后选出1个最近最少使用的
# 你可以直接使用以下的配置修改样本大小
#
# 默认的5 可以产生足够好的结果
# 10可以绝对的接近真正的LRU但是会消耗多一点CPU 
# 3 可以非常快但是不够精确
#
# maxmemory-samples 5
 
#############################APPEND ONLY MODE#############################
 
# 默认情况下Redis会异步的将数据集持久化到磁盘
# 这种模式对许多应用程序来说是足够的
# 但是当Redis进程产生问题或者断电时
# 可能导致短时间的写入丢失（由配置的保存点决定） 
#
# Append Only File 是一种供选择的持久化模式
# 可以提供好的多的高可用性
# 对于使用默认的数据fsync策略的实例（见配置文件后文）
# Redis在一个突发情况下仅仅会丢失一秒的写入
# 例如服务器断电，或一个写入时遭遇Redis进程问题但是操作系统依然运行良好
#
# AOF 和 RDB 持久化可以同时开启，并没有问题 
# 如果AOF 是开启的，Redis在启动的时候会加载AOF
# 该文件具有更好的高可用保障
#
# 详情请见 http://redis.io/topics/persistence 
appendonly no
 
# append only file 文件名(default: "appendonly.aof")
 
appendfilename "appendonly.aof"
 
# fsync() 调用告知操作系统立即写入数据到磁盘
# 而不是等待输出缓冲中的更多数据再写入
# 一些 OS 会真的flush数据到磁盘，而其他的OS则会尽快的仅仅尝试这么做 
#
# Redis 支持3种不同的模式
#
# no: 不使用 fsync, 交由OS掌握写入数据的时机，更快
# always: 在每次对append only log写之后均使用fsync ，慢，最安全
# everysec: 每秒进行一次fsync，折衷
#
# 默认为 "everysec"，是速度和数据安全之间的折衷，通常是正确的。
# 选择取决于你的理解，如果你想让要更好的性能就使用”no”
# 让操作系统决定何时写入，但是这样的话你必须可以容忍一些数据的丢失
# 因为默认的持久化模式为snapshot
# 或者相反，使用"always" 会很慢，但是比everysec更加安全
#
# 更多详情请见以下文章:
# http://antirez.com/post/redis-persistence-demystified.html
#
# 如果不确定, 请使用 "everysec".
 
# appendfsync always
appendfsync everysec
# appendfsync no
 
# 当 AOF fsync 策略设置为 always 或者 everysec, 
# 一个后台存储进程(后台存储或者AOF 日志后台重写)
# 在某些Linux配置下，会在磁盘上产生大量的 I/O操作
# Redis可能会阻塞fsync()调用很久
# 请注意当前没有办法修复这个，因为即使在不同的线程执行fsync
# 也会阻塞我们的synchronous write(2) 调用
#
# 为了减轻上述问题，可以使用以下的配置
# 它会防止在主线程中调用fsync()
# 当BGSAVE 或者 BGREWRITEAOF 在进行中时
#
# 这意味着当一个子线程在存储数据时
# Redis的高可用性相当于"appendfsync none" 
# 在实际中，这意味着在最坏的情况下（使用默认的Linux设置）
# 有可能丢失最多30秒的log
# 
# 如果你有延迟问题把它设置为 "yes"
# 否则的话请保持"no" ，这是最安全的，在高可用方面来看 
no-appendfsync-on-rewrite no
 
# 自动重写append only file.
# Redis 可以自动重写 log file 
# 通过静默调用BGREWRITEAOF，当AOF log的大小增长了指定的百分比时
# 
# 工作方式: Redis 会在最近一次重写AOF 文件后记住文件大小
# 如果重启后一次重写都没发生，就使用启动时的AOF大小
#
# 这个基准大小会和当前大小相比
# 如果当前大小大于了指定的百分比，重写就会被触发
# 你需要指定一个AOF文件被重写的最小大小
# 有效防止AOF文件达到了指定的增长百分比却仍然很小的情况下被重写
#
# 指定0百分比可以禁用自动重写AOF
 
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# 在Redis启动过程中，AOF数据重新载入内存时
# 一个AOF 文件可能会被发现在末尾遭受了删截
# 这在Redis运行的操作系统崩溃时可能发生
# 尤其是当一个ext4文件系统挂载时没有使用data=ordered选项时
# 但是当操作系统工作良好但是Redis自己崩溃或者终止时不会发生这种情况
#
# 如果发生了AOF文件末尾缺失情况，Redis会错误退出
#或者载入尽可能多的数据（默认设置）然后启动。
#
# 以下设置可以控制该行为 
#I如果aof-load-truncated 设置为yes, 删截的AOF文件会被载入
# 然后 Redis服务器会开始发送日志来通知用户该事件
# 相反，如果设置为no，服务器会错误终止并且拒绝启动
# 当设置为no，用户在重启服务器前需要使用"redis-check-aof"功能修复AOF文件
#
# 注意当发现AOF文件在中间被损坏时服务器也会错误退出
# 这个设置仅仅适用于Redis尝试从AOF文件读取更多数据却找不到足够的字节时
aof-load-truncated yes
 
################################ LUA 脚本  ###############################
 
# Lua 脚本的最大执行时间，单位毫秒
#
#如果达到了最大执行时间，Redis会日志记录脚本在最大允许执行时间后仍在运行
# 并且会开始回应错误给队列
#
# 当一个长时间运行的脚本超过了最大运行时间
# 只有SCRIPT KILL 和 SHUTDOWN NOSAVE 命令可用
# 第一个命令可以用来停止还未调用写入命令的脚本
# 第二个命令是用来关闭服务器的唯一方法
# 是为了脚本已经触发了写入命令但是用户不想等待脚本自然终止的情况
#
# 设置为0或一个负值可以情况下不限制执行时间，也不会有警告
lua-time-limit 5000
 
################################ REDIS 集群  ###############################
#
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# 实验性警告：Redis Cluster考虑称为稳定的代码
# 但是为了标记它为“成熟的” ，我们需要等待一个较多比例的用户在生产环境部署它
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# 普通的Redis实例无法成为Redis Cluster的一部分；
# 只有以集群节点启动的节点实例才可以
# 为了以一个集群节点的方式启动Redis实例
# 需要反注释下面设置来开启集群支持
# cluster-enabled yes
 
# 每一个集群节点有一个集群配置文件
# 这个文件不打算用手工编辑，它由Redis节点创建和更新
# 每一个Redis Cluster节点需要一个不同的集群配置文件
#确保运行在相同系统下的实例不存在重复的集群配置文件名
#
# cluster-config-file nodes-6379.conf
 
# 集群节点超时是一个毫秒值，一个节点超过该时间不可达则会被考虑已经处于失效状态
# 大部分的内部时间限制都是该值的倍数
#
# cluster-node-timeout 15000
 
# 失效master的一个slave会避免开始一个failover 流程如果它的数据看起来太陈旧
#
# 实际上没有简单的方法可以精确的度量一个slave的“数据年龄”
# 所以会执行以下的两种检查：
#
# 1) 如果有多个slaves可以进行failover，它们会交换消息为了
#   尝试给予具有最佳复制备份（由master传输了更多数据）的slave优势
#   Slaves 会尝试由备份情况获得它们的排序
#   然后以它们的排序成正比的优先级开始failover
#
# 2) 每一个单独的slave会计算最后一次和master交互的时间
#   这可以是最后一次ping或者受到指令（如果master仍处于“connected”状态）
#   或者是从它与master断开连接后经过的时间（如果复制链路当前已经断掉）
#   如果最后一次交互过于陈旧，那么这个slave根本不会尝试进行
#
# 第二店可以由用户进行调节。明确的指定一个slave不会进行failover
# 如果从最后一次和master交互开始，经过的时间大于以下值：
#
#   (node-timeout * slave-validity-factor) + repl-ping-slave-period
#
# 举个例子，如果 node-timeout 是 30 秒，slave-validity-factor
# 是10, 并且假设默认的repl-ping-slave-period 是10秒
# 那么slave不会尝试进行failover如果它超过了310秒不能与master正常通信
#
# 一个大的slave-validity-factor值可以允许具有过于陈旧的数据的slaves去failover为master
# 同时过于小的值则会阻止集群去选举一个slave
#
# 为了最大化可用性，可以设置slave-validity-factor为0
# slaves 会一直尝试failover为master
# 而忽略他们最后一次和master交互的时间
# (但是他们会一直应用它们的备份情况排序成正比的优先级）
#
# 0是唯一可以保证所有子部分都能帮助集群持续运行的值
#
# cluster-slave-validity-factor 10
 
# 集群slaves 可以迁移到孤立的masters，就是不存在有效slaves的masters
# 这提升了集群抵抗孤立master因为没有有效slaves而无法进行故障转移的能力
#
# 只有当slaves原来的master至少仍然有指定的数量的其他有效slaves时，
# Slaves才可以迁移到孤立masters。这个值为"migration barrier"
# 一个为1的migration barrier 意味着一个slave的master
# 至少还有一个或更多其他有效的slave时，这个slave才会迁移
# 这个值通常反应了你想要集群中的每个master拥有的slaves个数
#
# 默认值为1 (slaves仅当它们的masters仍然具有至少一个slave时才能迁移)
# 想关闭迁移可以设置一个非常大的值
# 可以设置为0但是仅可用于debug，用于生产是十分危险的。
#
# cluster-migration-barrier 1
 
# 为了部署你的集群，请确认阅读http://redis.io 网站的文档
 
#################################SLOW LOG##################################
 
# Redis Slow Log是用来记录超过一个指定执行时间问题的日志系统 
# 执行时间不包括I/O操作比如与客户端通信，发送回复等等
# 而是仅仅的执行命令实际所需的时间
# （指的是线程锁死并且不能同时服务其他请求的命令执行阶段）
# 
# 你可以用两个参数配置slow log：
# 一个告诉Redis超过的执行时间，单位是微秒，然后会日志记录下该命令
# 然后另一个参数是slow log的长度
# 当一个新命令被日志记录，旧的那个就会在日志记录的命令队列里移除
 
# 以下的时间以微秒为单位所以1000000和1秒是等价的 
# 注意一个负值会禁用slow log，0则会强制日志记录每一个命令
slowlog-log-slower-than 10000
 
# 该长度没有限制，请知晓那样会消耗内存
# 你可以通过SLOWLOG RESET来回收slow log使用的内存
slowlog-max-len 128
 
################################ 延迟监控器 ##############################

# Redis延迟监控器子系统在运行时采样不同操作
# 为了收集可能与Redis实例延迟相关的源数据
#
# 通过LATENCY命令，用户可以使用该信息，打印图表和获取报告
#
# 这个系统仅会日志记录执行时间等于或大于指定毫秒值的操作
# 直接通过latency-monitor-threshold设置
# 当它的值设置为0时，延迟监控器关闭
#
# 延迟监控器默认是关闭的，因为如果你没有延迟问题，大多数情况下不需要
# 高负荷的情况下，收集数据会影响性能，虽然很小
# 如果需要，监控可以在运行时很容易的开启，使用命令
# "CONFIG SET latency-monitor-threshold <milliseconds>"
latency-monitor-threshold 0

############################# 事件通知 ##############################
 
# Redis可以通知Pub/Sub客户端关于key空间发生的事件
# 这个特性文档说明在http://redis.io/topics/keyspace-events
# 
# 举例，比如key空间事件通知开启了，
# 然后一个客户端执行了存储在数据库0上的key "foo"上的DEL操作 two
# 两条消息就会通过Pub/Sub发布：
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# 可以在以下类集合中选择Redis会通知的事件
# 每一类都以一个单独的字符进行标识
#
#  K     Keyspace事件, 以 __keyspace@<db>__ prefix格式发布
#  E     Keyevent 事件, 以__keyevent@<db>__ prefix格式发布
#  g     通用命令 (不指定类型) 比如DEL, EXPIRE, RENAME, ...
#  $     String命令
#  l     List命令
#  s     Set命令
#  h     Hash命令
#  z     Sorted set命令
#  x     Expired 事件 （每次key过期生成的事件）
#  e     Evicted 事件（每次超过最大内存限制移除key生成的时间）
#  A     g$lshzxe的别名, 所以字符串"AKE"代表所有事件
#
#  "notify-keyspace-events"是由0个或多个字符组成的参数字符串
#  空字符串表示关闭通知功能
#
#  例子：想开启list和通用事件，那么从事件名来看，就使用：
#
#  notify-keyspace-events Elg
#
#  例子2：想获得过期key的流，订阅消息通道__keyevent@0__:expired，就使用
#
#  notify-keyspace-events Ex
#
#  默认所有通知都是关闭的因为大部分用户不需要此功能并且此功能有一些开销
#  注意如果你没有指定K或者E中的至少一个，没有事件会被发送
notify-keyspace-events ""
 
############################### 高级设置 ###############################
 
# 当Hashes具有小数量的entries使用高效内存数据结构进行编码
# 从而最大的entry不能超过一个给定的阈值
# 这些阈值可以直接通过以下进行配置
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
 
# 同hashes类似，小的lists为了节省大量空间，也用一种特殊方式编码
# 只有当处于以下限制中时这种特殊的表示形式才会使用
list-max-ziplist-entries 512
list-max-ziplist-value 64
 
# Sets只有在一种情况下会特殊编码
# 当一个set仅由64位带符号十进制整数字符串组成时
# 以下的配置项用于设置为了使用这种特殊内存节省编码方案时的set的容量限制
set-max-intset-entries 512
 
# 和hashes与lists类似，sorted sets为了节省大量空间也特殊化编码
# 这个编码方式仅当sorted sets的长度及元素低于以下限制时使用
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
 
# HyperLogLog稀疏表示形式的字节限制，这个限制包含16字节的头
# 当一个使用稀疏表示形式的HyperLogLog超过该限制时
# 它会转变成稠密表示形式
#
# 一个大于16000的值是完全没有作用的
# 因为在那个点上稠密表现形式是更内存高效的
# 
# 推荐的值是~ 3000 
# 为了具有高效空间编码的优势却不会太多的减慢PFADD命令
# 它在稀疏编码下复杂度O(N)
# 这个值可以提升到~ 10000当不必考虑CPU却需要考虑空间时
# 此时数据集由许多以 0 - 15000范围内为基数的HyperLogLogs组成
hll-sparse-max-bytes 3000
 
# 为了帮助重哈希主Redis哈希表（映射高级别的键值对的表）
# 进行重哈希会使用每100毫秒的CPU时间中的1毫秒
# 哈希表实现了Redis uses接口(see dict.c)
# 进行惰性重哈希：在进行重哈希的哈希表上进行越多操作
# 越多的重哈希“步骤”就会被执行
# 所以如果服务器空闲时进行重哈希没有完成，那么哈希表就会使用一些更多的内存
# 
# 默认是每秒使用这个毫秒10次，为了进行主字典的重哈希，同时在可能时释放内存
#
# 如果不确定：
# 如果你有严格的延迟要求
# 并且Redis每次回复队列之间有2毫秒的延迟在你的环境中不是一件好事
# 使用"activerehashing no" 
#
# 如果你没有如此严格的要求但是想要在可能时尽快释放内存
# 使用"activerehashing yes"
activerehashing yes
 
# 客户端输出缓冲限制可以被用来强制断开某些客户端连接
# 它们因为一些原因不能从服务器足够快的读取数据
#（一个常见的原因就是Pub/Sub的客户端不能像发布端生产信息同样快的消费掉信息） 
#
# 这个限制可以为以下3中不同类型的客户端分别设置
#
# normal -> 普通客户端clients
# slave  -> slave客户端和MONITOR客户端
# pubsub -> 至少订阅了一个pubsub channel或者 pattern的客户端
#
# 每个client-output-buffer-limit 的语法可以直接按照如下：
#
# client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>
#
# 一个客户端一旦达到hard limit 的值就会立即断开
# 或者达到了soft limit然后仍然维持了指定的秒数就会断开（持续的）
# 所以举例来说，如果hard limit是32mb，soft limit 是16mb/10秒
# 那么客户端在输出缓冲大小达到32mb时会立即断开连接
# 或者如果客户端达到16mb然后持续的超过该限制10秒，也会断开
#
# 默认情况普通的客户端不会受限制
# 因为它们不会不主动请求就接收数据（不会处于推送方式）
# 因此异步的客户端可能创建出请求数据比它可读更快的场景
#
# 不同的是对于pubsub和slave客户端有一个默认的限制
# 因为订阅者和slaves接受数据是处于推送的方式
#
# hard 或者soft limit 都可以通过设置为0来禁用
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
 
# Redis调用一个内部功能去进行许多后台任务
# 比如关闭超时客户端的连接，清除从来没有请求过的过期键值等等
#
# 并不是所有的任务都以相同的频率进行
# 而是Redis通过检查指定的"hz"值来执行任务
#
# 默认"hz" 设置为10，增加该值Redis会在空闲时使用更多的CPU 
# 但是同时会使Redis在同时具有很多过期键值时更具响应性
# 然后超时也可以被更精确的处理
#
# 范围是1到500，但是超过100的值通常不是个好主意
# 大多数用户应该使用默认的10
# 如果环境需要非常低的延迟才提升到100 
hz 10
 
# 当一个子进程重写AOF文件时，如果以下的选项开启
# 文件会在每生成32MB数据时被fsync
# 为了更加递增的提交文件到磁盘，避免大的延迟突变
aof-rewrite-incremental-fsync yes